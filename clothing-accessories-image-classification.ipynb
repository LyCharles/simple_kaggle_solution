{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ed49a37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T08:58:01.711566Z",
     "iopub.status.busy": "2024-07-10T08:58:01.711245Z",
     "iopub.status.idle": "2024-07-10T08:58:15.546114Z",
     "shell.execute_reply": "2024-07-10T08:58:15.544835Z"
    },
    "papermill": {
     "duration": 13.8402,
     "end_time": "2024-07-10T08:58:15.548219",
     "exception": false,
     "start_time": "2024-07-10T08:58:01.708019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (3.6.1)\r\n",
      "Collecting optuna-integration\r\n",
      "  Downloading optuna_integration-3.6.0-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.13.1)\r\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna) (6.8.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (21.3)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (2.0.25)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna) (4.66.4)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0.1)\r\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.5)\r\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.9.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.1.1)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\r\n",
      "Downloading optuna_integration-3.6.0-py3-none-any.whl (93 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.4/93.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: optuna-integration\r\n",
      "Successfully installed optuna-integration-3.6.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna optuna-integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0575da7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-10T08:58:15.556110Z",
     "iopub.status.busy": "2024-07-10T08:58:15.555794Z",
     "iopub.status.idle": "2024-07-10T10:14:12.125984Z",
     "shell.execute_reply": "2024-07-10T10:14:12.124819Z"
    },
    "papermill": {
     "duration": 4556.577088,
     "end_time": "2024-07-10T10:14:12.128422",
     "exception": false,
     "start_time": "2024-07-10T08:58:15.551334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-10 08:58:29,963] A new study created in memory with name: no-name-ffd0cd9f-4613-4450-818c-75dab5a29c9f\n",
      "[I 2024-07-10 09:01:56,601] Trial 0 finished with value: 0.6518333333333334 and parameters: {'learning_rate': 1.8031154903906834e-05, 'momentum': 0.5840082878404524}. Best is trial 0 with value: 0.6518333333333334.\n",
      "[I 2024-07-10 09:05:21,344] Trial 1 finished with value: 0.9379166666666666 and parameters: {'learning_rate': 0.08451647465228938, 'momentum': 0.6566039081648753}. Best is trial 1 with value: 0.9379166666666666.\n",
      "[I 2024-07-10 09:08:45,605] Trial 2 finished with value: 0.8534166666666667 and parameters: {'learning_rate': 0.0002622692155832004, 'momentum': 0.5432511360462362}. Best is trial 1 with value: 0.9379166666666666.\n",
      "[I 2024-07-10 09:12:11,507] Trial 3 finished with value: 0.9365833333333333 and parameters: {'learning_rate': 0.0946087480443934, 'momentum': 0.5970137316230999}. Best is trial 1 with value: 0.9379166666666666.\n",
      "[I 2024-07-10 09:15:37,859] Trial 4 finished with value: 0.80775 and parameters: {'learning_rate': 5.36718353425734e-05, 'momentum': 0.8401574536308052}. Best is trial 1 with value: 0.9379166666666666.\n",
      "[I 2024-07-10 09:19:03,179] Trial 5 finished with value: 0.92175 and parameters: {'learning_rate': 0.0004900519665392745, 'momentum': 0.8941065623949763}. Best is trial 1 with value: 0.9379166666666666.\n",
      "[I 2024-07-10 09:22:29,585] Trial 6 finished with value: 0.9371666666666667 and parameters: {'learning_rate': 0.08589118911884529, 'momentum': 0.6798047603048002}. Best is trial 1 with value: 0.9379166666666666.\n",
      "[I 2024-07-10 09:22:39,917] Trial 7 pruned. \n",
      "[I 2024-07-10 09:22:50,189] Trial 8 pruned. \n",
      "[I 2024-07-10 09:26:14,673] Trial 9 finished with value: 0.9385 and parameters: {'learning_rate': 0.07199706570623239, 'momentum': 0.6800596973992137}. Best is trial 9 with value: 0.9385.\n",
      "[I 2024-07-10 09:29:39,530] Trial 10 finished with value: 0.9328333333333333 and parameters: {'learning_rate': 0.008501007702807215, 'momentum': 0.7780391181314661}. Best is trial 9 with value: 0.9385.\n",
      "[I 2024-07-10 09:33:04,882] Trial 11 finished with value: 0.9354166666666667 and parameters: {'learning_rate': 0.01727823339413699, 'momentum': 0.6751076014727017}. Best is trial 9 with value: 0.9385.\n",
      "[I 2024-07-10 09:36:29,515] Trial 12 finished with value: 0.9345 and parameters: {'learning_rate': 0.01605641768136952, 'momentum': 0.6333003221878496}. Best is trial 9 with value: 0.9385.\n",
      "[I 2024-07-10 09:36:39,851] Trial 13 pruned. \n",
      "[I 2024-07-10 09:40:04,713] Trial 14 finished with value: 0.9379166666666666 and parameters: {'learning_rate': 0.038160145873311534, 'momentum': 0.7094213069999}. Best is trial 9 with value: 0.9385.\n",
      "[I 2024-07-10 09:41:36,573] Trial 15 pruned. \n",
      "[I 2024-07-10 09:41:46,886] Trial 16 pruned. \n",
      "[I 2024-07-10 09:41:57,213] Trial 17 pruned. \n",
      "[I 2024-07-10 09:45:21,842] Trial 18 finished with value: 0.93975 and parameters: {'learning_rate': 0.04332021300219847, 'momentum': 0.713331254778012}. Best is trial 18 with value: 0.93975.\n",
      "[I 2024-07-10 09:48:46,063] Trial 19 finished with value: 0.9385833333333333 and parameters: {'learning_rate': 0.04124526627344254, 'momentum': 0.7244073786204464}. Best is trial 18 with value: 0.93975.\n",
      "[I 2024-07-10 09:48:56,413] Trial 20 pruned. \n",
      "[I 2024-07-10 09:49:27,224] Trial 21 pruned. \n",
      "[I 2024-07-10 09:49:37,656] Trial 22 pruned. \n",
      "[I 2024-07-10 09:51:09,781] Trial 23 pruned. \n",
      "[I 2024-07-10 09:53:02,750] Trial 24 pruned. \n",
      "[I 2024-07-10 09:53:13,091] Trial 25 pruned. \n",
      "[I 2024-07-10 09:53:23,328] Trial 26 pruned. \n",
      "[I 2024-07-10 09:53:33,594] Trial 27 pruned. \n",
      "[I 2024-07-10 09:53:43,915] Trial 28 pruned. \n",
      "[I 2024-07-10 09:53:54,191] Trial 29 pruned. \n",
      "[I 2024-07-10 09:54:04,448] Trial 30 pruned. \n",
      "[I 2024-07-10 09:55:56,760] Trial 31 pruned. \n",
      "[I 2024-07-10 09:57:48,984] Trial 32 pruned. \n",
      "[I 2024-07-10 09:58:09,554] Trial 33 pruned. \n",
      "[I 2024-07-10 09:58:19,839] Trial 34 pruned. \n",
      "[I 2024-07-10 09:58:30,186] Trial 35 pruned. \n",
      "[I 2024-07-10 09:58:40,422] Trial 36 pruned. \n",
      "[I 2024-07-10 10:02:04,557] Trial 37 finished with value: 0.93725 and parameters: {'learning_rate': 0.0992635418957186, 'momentum': 0.5515343071420137}. Best is trial 18 with value: 0.93975.\n",
      "[I 2024-07-10 10:05:28,421] Trial 38 finished with value: 0.9383333333333334 and parameters: {'learning_rate': 0.015659665172507085, 'momentum': 0.871690396172063}. Best is trial 18 with value: 0.93975.\n",
      "[I 2024-07-10 10:05:48,866] Trial 39 pruned. \n",
      "[I 2024-07-10 10:05:59,097] Trial 40 pruned. \n",
      "[I 2024-07-10 10:06:19,497] Trial 41 pruned. \n",
      "[I 2024-07-10 10:06:40,044] Trial 42 pruned. \n",
      "[I 2024-07-10 10:06:50,386] Trial 43 pruned. \n",
      "[I 2024-07-10 10:07:10,882] Trial 44 pruned. \n",
      "[I 2024-07-10 10:07:41,532] Trial 45 pruned. \n",
      "[I 2024-07-10 10:08:02,018] Trial 46 pruned. \n",
      "[I 2024-07-10 10:08:12,190] Trial 47 pruned. \n",
      "[I 2024-07-10 10:08:22,541] Trial 48 pruned. \n",
      "[I 2024-07-10 10:08:32,814] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.04332021300219847, 'momentum': 0.713331254778012}\n",
      "Epoch 1, Loss: 0.5087731792330742\n",
      "Epoch 2, Loss: 0.29984266999860604\n",
      "Epoch 3, Loss: 0.2399582008620103\n",
      "Epoch 4, Loss: 0.20744726993888615\n",
      "Epoch 5, Loss: 0.1736084934224685\n",
      "Epoch 6, Loss: 0.15172170426448187\n",
      "Epoch 7, Loss: 0.1312965278290212\n",
      "Epoch 8, Loss: 0.11319389846175909\n",
      "Epoch 9, Loss: 0.09444059476070106\n",
      "Epoch 10, Loss: 0.0823770273051535\n",
      "Epoch 11, Loss: 0.03542361423559487\n",
      "Epoch 12, Loss: 0.01964785945112817\n",
      "Epoch 13, Loss: 0.013744457902774836\n",
      "Epoch 14, Loss: 0.009740920906808849\n",
      "Epoch 15, Loss: 0.007270199733204208\n",
      "Epoch 16, Loss: 0.005357571788481437\n",
      "Epoch 17, Loss: 0.004074703407318641\n",
      "Epoch 18, Loss: 0.0034983431485209925\n",
      "Epoch 19, Loss: 0.0031050509937340393\n",
      "Epoch 20, Loss: 0.0022876731814855398\n",
      "Epoch 21, Loss: 0.002217207046788341\n",
      "Epoch 22, Loss: 0.0021340811376576313\n",
      "Epoch 23, Loss: 0.0020340104892966338\n",
      "Epoch 24, Loss: 0.0021526384179596787\n",
      "Epoch 25, Loss: 0.0020113590456506546\n",
      "Epoch 26, Loss: 0.001978873900147543\n",
      "Epoch 27, Loss: 0.0018270632766070776\n",
      "Epoch 28, Loss: 0.0019467859618113531\n",
      "Epoch 29, Loss: 0.0017680633622415675\n",
      "Epoch 30, Loss: 0.0020228504217617836\n",
      "Epoch 31, Loss: 0.0017561453412636182\n",
      "Epoch 32, Loss: 0.001633659208882212\n",
      "Epoch 33, Loss: 0.001881855260018104\n",
      "Epoch 34, Loss: 0.0017441859020618721\n",
      "Epoch 35, Loss: 0.0018911628857216176\n",
      "Validation Accuracy: 93.58333333333333%\n",
      "       label\n",
      "ID          \n",
      "60001      7\n",
      "60002      5\n",
      "60003      4\n",
      "60004      5\n",
      "60005      8\n",
      "...      ...\n",
      "69996      3\n",
      "69997      7\n",
      "69998      0\n",
      "69999      9\n",
      "70000      6\n",
      "\n",
      "[10000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# 定义SpinalVGG模型\n",
    "Half_width = 128\n",
    "layer_width = 128\n",
    "\n",
    "class SpinalVGG(nn.Module):\n",
    "    def two_conv_pool(self, in_channels, f1, f2):\n",
    "        s = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, f1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(f1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(f1, f2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(f2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        for m in s.children():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        return s\n",
    "    \n",
    "    def three_conv_pool(self, in_channels, f1, f2, f3):\n",
    "        s = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, f1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(f1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(f1, f2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(f2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(f2, f3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(f3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        for m in s.children():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        return s\n",
    "        \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SpinalVGG, self).__init__()\n",
    "        self.l1 = self.two_conv_pool(1, 64, 64)\n",
    "        self.l2 = self.two_conv_pool(64, 128, 128)\n",
    "        self.l3 = self.three_conv_pool(128, 256, 256, 256)\n",
    "        self.l4 = self.three_conv_pool(256, 256, 256, 256)\n",
    "        \n",
    "        self.fc_spinal_layer1 = nn.Sequential(\n",
    "            nn.Dropout(p=0.5), nn.Linear(Half_width, layer_width),\n",
    "            nn.BatchNorm1d(layer_width), nn.ReLU(inplace=True))\n",
    "        self.fc_spinal_layer2 = nn.Sequential(\n",
    "            nn.Dropout(p=0.5), nn.Linear(Half_width+layer_width, layer_width),\n",
    "            nn.BatchNorm1d(layer_width), nn.ReLU(inplace=True))\n",
    "        self.fc_spinal_layer3 = nn.Sequential(\n",
    "            nn.Dropout(p=0.5), nn.Linear(Half_width+layer_width, layer_width),\n",
    "            nn.BatchNorm1d(layer_width), nn.ReLU(inplace=True))\n",
    "        self.fc_spinal_layer4 = nn.Sequential(\n",
    "            nn.Dropout(p=0.5), nn.Linear(Half_width+layer_width, layer_width),\n",
    "            nn.BatchNorm1d(layer_width), nn.ReLU(inplace=True))\n",
    "        self.fc_out = nn.Sequential(\n",
    "            nn.Dropout(p=0.5), nn.Linear(layer_width*4, num_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.l3(x)\n",
    "        x = self.l4(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x1 = self.fc_spinal_layer1(x[:, 0:Half_width])\n",
    "        x2 = self.fc_spinal_layer2(torch.cat([x[:, Half_width:2*Half_width], x1], dim=1))\n",
    "        x3 = self.fc_spinal_layer3(torch.cat([x[:, 0:Half_width], x2], dim=1))\n",
    "        x4 = self.fc_spinal_layer4(torch.cat([x[:, Half_width:2*Half_width], x3], dim=1))\n",
    "        \n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        x = torch.cat([x, x3], dim=1)\n",
    "        x = torch.cat([x, x4], dim=1)\n",
    "        \n",
    "        x = self.fc_out(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# 加载和预处理数据\n",
    "train_url = \"https://www.dropbox.com/scl/fi/6tgxge3y0jot8075d5lng/train_imageclass.csv?rlkey=b4cj2ifgbzjlrcmals3t98eu2&st=zmwpkgke&dl=0&raw=1\"\n",
    "df_train = pd.read_csv(train_url, index_col='ID')\n",
    "\n",
    "target_col = 'label'\n",
    "X_train = df_train.drop(columns='label').values\n",
    "y_train = df_train['label'].values\n",
    "\n",
    "# Reshaping x_train into 2D and normalize\n",
    "X_train = X_train.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
    "\n",
    "# One-hot encoding of labels\n",
    "num_classes = 10\n",
    "y_train = np.eye(num_classes)[y_train.reshape(-1)]\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train).permute(0, 3, 1, 2).to(torch.float32)\n",
    "y_train = torch.tensor(y_train).to(torch.float32)\n",
    "X_val = torch.tensor(X_val).permute(0, 3, 1, 2).to(torch.float32)\n",
    "y_val = torch.tensor(y_val).to(torch.float32)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_val, y_val), batch_size=64, shuffle=False)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def objective(trial):\n",
    "    # 定义超参数搜索空间\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
    "    momentum = trial.suggest_float('momentum', 0.5, 0.9)\n",
    "    \n",
    "    # 初始化模型和优化器\n",
    "    network = SpinalVGG(num_classes=num_classes).to(device)\n",
    "    optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    \n",
    "    # 定义损失函数\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # 训练模型\n",
    "    num_epochs = 20\n",
    "    for epoch in range(num_epochs):\n",
    "        network.train()\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels.argmax(dim=1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # 验证模型\n",
    "        network.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = network(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels.argmax(dim=1)).sum().item()\n",
    "        accuracy = correct / total\n",
    "        trial.report(accuracy, epoch)\n",
    "        \n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# 运行Optuna超参数优化\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# 获取最佳超参数\n",
    "best_params = study.best_params\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# 使用最佳超参数重新训练模型\n",
    "learning_rate = best_params['learning_rate']\n",
    "momentum = best_params['momentum']\n",
    "network = SpinalVGG(num_classes=num_classes).to(device)\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 35\n",
    "for epoch in range(num_epochs):\n",
    "    network.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = network(inputs)\n",
    "        loss = criterion(outputs, labels.argmax(dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    scheduler.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')\n",
    "\n",
    "# 评估模型\n",
    "network.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = network(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.argmax(dim=1)).sum().item()\n",
    "print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "# 预测测试集\n",
    "test_url = \"https://www.dropbox.com/scl/fi/r8tjg2dea59q5timei3dg/test_imageclass.csv?rlkey=1dzvhckz1x9x3e05vgp00lm6f&st=qnmdgala&dl=0&raw=1\"\n",
    "df_test = pd.read_csv(test_url, index_col='ID')\n",
    "X_test = df_test.values.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
    "X_test = torch.tensor(X_test).permute(0, 3, 1, 2).to(torch.float32).to(device)\n",
    "\n",
    "network.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = network(X_test)\n",
    "    y_pred = y_pred.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "# 将预测结果转换为CSV文件\n",
    "submission = pd.DataFrame(y_pred, index=df_test.index, columns=[target_col])\n",
    "submission.to_csv('submission.csv')\n",
    "\n",
    "print(submission)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8919269,
     "sourceId": 81977,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4574.906735,
   "end_time": "2024-07-10T10:14:13.871554",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-10T08:57:58.964819",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
